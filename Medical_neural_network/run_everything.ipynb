{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa06a70b-fb7b-4b33-9782-ec8eb6013673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from util.util import importstr\n",
    "from util.logconf import logging\n",
    "log = logging.getLogger('nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cfe580-6cc5-4e18-9868-533826e607a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(app, *argv):\n",
    "    argv = list(argv)\n",
    "    argv.insert(0, f'--num-workers={multiprocessing.cpu_count()}')\n",
    "    log.info(f\"Running: {app}({argv!r}).main()\")\n",
    "\n",
    "    app_cls = importstr(*app.rsplit('.', 1))\n",
    "    app_cls(argv).main()\n",
    "\n",
    "    log.info(f\"Finished: {app}.{argv!r}.main()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd497ed8cea8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 20\n",
    "experiment_epochs = 10\n",
    "final_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62fa8155-f74d-4ccf-a3b0-69b577e3cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 22:00:25,525 INFO     pid:22008 nb:004:run Running: prepcache.LunaPrepCacheApp(['--num-workers=8']).main()\n",
      "2024-05-03 22:00:28,968 INFO     pid:22008 prepcache:036:main Starting LunaPrepCacheApp, Namespace(batch_size=1024, num_workers=8)\n",
      "2024-05-03 22:00:30,687 INFO     pid:22008 dsets:182:__init__ <dsets.LunaDataset object at 0x000001DC2E8F72B0>: 56938 training samples\n",
      "2024-05-03 22:00:30,688 WARNING  pid:22008 util.util:146:enumerateWithEstimate Stuffing cache ----/56, starting\n",
      "2024-05-03 22:01:43,624 INFO     pid:22008 util.util:163:enumerateWithEstimate Stuffing cache   16/56, done at 2024-05-03 22:03:18, 0:01:56\n",
      "2024-05-03 22:02:28,683 INFO     pid:22008 util.util:163:enumerateWithEstimate Stuffing cache   32/56, done at 2024-05-03 22:03:30, 0:02:08\n",
      "2024-05-03 22:03:16,686 WARNING  pid:22008 util.util:176:enumerateWithEstimate Stuffing cache ----/56, done at 2024-05-03 22:03:16\n",
      "2024-05-03 22:03:16,706 INFO     pid:22008 nb:009:run Finished: prepcache.LunaPrepCacheApp.['--num-workers=8'].main()\n"
     ]
    }
   ],
   "source": [
    "run('prepcache.LunaPrepCacheApp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa69e47-ae36-4467-b4ea-444182ae1f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 22:03:16,722 INFO     pid:22008 nb:004:run Running: training.LunaTrainingApp(['--num-workers=8', '--epochs=1']).main()\n",
      "2024-05-03 22:03:18,327 INFO     pid:22008 training:134:main Starting LunaTrainingApp, Namespace(num_workers=8, batch_size=32, epochs=1, tb_prefix='mnn', comment='dwlpt')\n",
      "2024-05-03 22:03:18,348 INFO     pid:22008 dsets:182:__init__ <dsets.LunaDataset object at 0x000001DC2E8F7190>: 51244 training samples\n",
      "2024-05-03 22:03:18,353 INFO     pid:22008 dsets:182:__init__ <dsets.LunaDataset object at 0x000001DC46DC18D0>: 5694 validation samples\n",
      "2024-05-03 22:03:18,354 INFO     pid:22008 training:140:main Epoch 1 of 1, 1602/178 batches of size 32*1\n",
      "2024-05-03 22:03:18,357 WARNING  pid:22008 util.util:146:enumerateWithEstimate E1 Training ----/1602, starting\n",
      "2024-05-03 22:05:21,359 INFO     pid:22008 util.util:163:enumerateWithEstimate E1 Training   64/1602, done at 2024-05-03 22:45:44, 0:41:53\n",
      "2024-05-03 22:09:09,563 INFO     pid:22008 util.util:163:enumerateWithEstimate E1 Training  256/1602, done at 2024-05-03 22:37:47, 0:33:56\n",
      "2024-05-03 22:24:12,104 INFO     pid:22008 util.util:163:enumerateWithEstimate E1 Training 1024/1602, done at 2024-05-03 22:35:44, 0:31:53\n",
      "2024-05-03 22:35:27,574 WARNING  pid:22008 util.util:176:enumerateWithEstimate E1 Training ----/1602, done at 2024-05-03 22:35:27\n",
      "2024-05-03 22:35:27,580 INFO     pid:22008 training:242:log_metrics E1 LunaTrainingApp\n",
      "2024-05-03 22:35:27,595 INFO     pid:22008 training:272:log_metrics E1 trn      0.0231 loss,  99.8% correct, \n",
      "2024-05-03 22:35:27,595 INFO     pid:22008 training:281:log_metrics E1 trn_neg  0.0024 loss, 100.0% correct (51135 of 51135)\n",
      "2024-05-03 22:35:27,596 INFO     pid:22008 training:292:log_metrics E1 trn_pos  9.7601 loss,   0.0% correct (0 of 109)\n",
      "2024-05-03 22:35:27,633 WARNING  pid:22008 util.util:146:enumerateWithEstimate E1 Validation  ----/178, starting\n",
      "2024-05-03 22:36:00,131 INFO     pid:22008 util.util:163:enumerateWithEstimate E1 Validation    64/178, done at 2024-05-03 22:36:23, 0:00:35\n",
      "2024-05-03 22:36:24,285 WARNING  pid:22008 util.util:176:enumerateWithEstimate E1 Validation  ----/178, done at 2024-05-03 22:36:24\n",
      "2024-05-03 22:36:24,287 INFO     pid:22008 training:242:log_metrics E1 LunaTrainingApp\n",
      "2024-05-03 22:36:24,289 INFO     pid:22008 training:272:log_metrics E1 val      0.0183 loss,  99.8% correct, \n",
      "2024-05-03 22:36:24,289 INFO     pid:22008 training:281:log_metrics E1 val_neg  0.0004 loss, 100.0% correct (5681 of 5681)\n",
      "2024-05-03 22:36:24,291 INFO     pid:22008 training:292:log_metrics E1 val_pos  7.8655 loss,   0.0% correct (0 of 13)\n",
      "2024-05-03 22:36:24,299 INFO     pid:22008 nb:009:run Finished: training.LunaTrainingApp.['--num-workers=8', '--epochs=1'].main()\n"
     ]
    }
   ],
   "source": [
    "run('training.LunaTrainingApp', '--epochs=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c230db7d428107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 22:36:24,318 INFO     pid:22008 nb:004:run Running: training.LunaTrainingApp(['--num-workers=8', '--epochs=10']).main()\n",
      "2024-05-03 22:36:24,329 INFO     pid:22008 training:134:main Starting LunaTrainingApp, Namespace(num_workers=8, batch_size=32, epochs=10, tb_prefix='mnn', comment='dwlpt')\n",
      "2024-05-03 22:36:24,370 INFO     pid:22008 dsets:182:__init__ <dsets.LunaDataset object at 0x000001DC43E6FDC0>: 51244 training samples\n",
      "2024-05-03 22:36:24,378 INFO     pid:22008 dsets:182:__init__ <dsets.LunaDataset object at 0x000001DC4F160880>: 5694 validation samples\n",
      "2024-05-03 22:36:24,379 INFO     pid:22008 training:140:main Epoch 1 of 10, 1602/178 batches of size 32*1\n",
      "2024-05-03 22:36:24,381 WARNING  pid:22008 util.util:146:enumerateWithEstimate E1 Training ----/1602, starting\n",
      "2024-05-03 22:38:01,614 INFO     pid:22008 util.util:163:enumerateWithEstimate E1 Training   64/1602, done at 2024-05-03 23:08:31, 0:31:37\n",
      "2024-05-03 22:41:48,556 INFO     pid:22008 util.util:163:enumerateWithEstimate E1 Training  256/1602, done at 2024-05-03 23:08:20, 0:31:27\n",
      "2024-05-03 22:56:52,272 INFO     pid:22008 util.util:163:enumerateWithEstimate E1 Training 1024/1602, done at 2024-05-03 23:08:12, 0:31:18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining.LunaTrainingApp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--epochs=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexperiment_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(app, *argv)\u001b[0m\n\u001b[0;32m      4\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margv\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).main()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m app_cls \u001b[38;5;241m=\u001b[39m importstr(\u001b[38;5;241m*\u001b[39mapp\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m \u001b[43mapp_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margv\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.main()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ilyas\\MedicalNN\\Medical-neural-network\\Medical_neural_network\\training.py:149\u001b[0m, in \u001b[0;36mLunaTrainingApp.main\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_ndx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcli_args\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    140\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m batches of size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    141\u001b[0m         epoch_ndx,\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcli_args\u001b[38;5;241m.\u001b[39mepochs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m         (torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cuda \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    147\u001b[0m     ))\n\u001b[1;32m--> 149\u001b[0m     trnMetrics_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_ndx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_metrics(epoch_ndx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrn\u001b[39m\u001b[38;5;124m'\u001b[39m, trnMetrics_t)\n\u001b[0;32m    152\u001b[0m     valMetrics_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_validation(epoch_ndx, val_dl)\n",
      "File \u001b[1;32mc:\\Users\\ilyas\\MedicalNN\\Medical-neural-network\\Medical_neural_network\\training.py:182\u001b[0m, in \u001b[0;36mLunaTrainingApp.do_training\u001b[1;34m(self, epoch_ndx, train_dl)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    175\u001b[0m     loss_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_batch_loss(\n\u001b[0;32m    176\u001b[0m         batch_ndx,\n\u001b[0;32m    177\u001b[0m         batch_tup,\n\u001b[0;32m    178\u001b[0m         train_dl\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m    179\u001b[0m         trnMetrics_g\n\u001b[0;32m    180\u001b[0m     )\n\u001b[1;32m--> 182\u001b[0m     \u001b[43mloss_var\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotalTrainingSamples_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dl\u001b[38;5;241m.\u001b[39mdataset)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run('training.LunaTrainingApp', f'--epochs={experiment_epochs}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
